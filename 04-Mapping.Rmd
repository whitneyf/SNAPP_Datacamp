---
title: "04-Mapping.Rmd"
author: "Whitney"
date: "2/21/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Geospatial analysis 

# Mapping with the `sf` package
(Jeanette)

[Ch 17](https://science-for-nature-and-people.github.io/2020-data-collab-workshop/2020-02-snapp/spatial-vector-analysis-using-sf.html)

SF: An R implementation of the SIMPLE FEATURES standard. (A newer, better version of `sp`)

HINT: Create a simplified version of a dataset (not high res) for code testing. 

## Setup 
* Go to https://dev.nceas.ucsb.edu/view/urn:uuid:6f07cb25-a4a1-48e8-95cb-74f532f3ce2d
* Copy link to shapefile.

Terminal: 

* mkdir data
* cd data
* wget -O data.zip https://dev.nceas.ucsb.edu/knb/d1/mn/v2/object/urn%3Auuid%3Aaceaecb2-1ce0-4d41-a839-d3607d32bb58
* -O: option to rename
* unzip data.zip
* ls

## Load libraries
```{r}
library(sf)
library(dplyr)
library(ggplot2)
library(scales)
library(ggmap)
library(leaflet)
```

## Read data
* shp file contains points in geospatial data
* every sf object contans a coordinate reference system (CRS)
* datum -  defines 3-D coordinates in space
* projection - how to represent the sphere on a 2-d surface
* datum + projection = CRS
* EPSG code: e.g. '4326' (corresponds to 'WGS84' - a datum). This is what GPS units typically collect. 
* [epsg.io](http://epsg.io/) : look up coordinate systems


```{r}
ak_regions <- read_sf("data/ak_regions_simp.shp") # read shapefile using sf 
plot(ak_regions)    # quick look using base R
class(ak_regions)   # sf object
head(ak_regions)
st_crs(ak_regions)  # check the crs
```
### Transform CRS
To a better 'projection' for Alaska
Two main types of projection: 
* 'Degree', e.g. WGS84
* 'Projected' projection - metric unit, like ft. Go from sphere to flat. Depending on where you are on the earth want a different projection :. many types. 

Also 
* 'Equal area projections', 'equal distance projections'. Can't have both simultaneously. Depends on your calculations. 
```{r}

# Often there's several versions of an object in a different CRS
# Nice to name object with the CRS to keep track.
ak_regions_3338 <- ak_regions %>% 
  st_transform(crs = 3338)

st_crs(ak_regions_3338)
plot(ak_regions_3338)

ak_regions_3338 %>% 
  filter(region == "Southeast") %>% 
  select(region)

```

## Read in population data
```{r}
pop <- read.csv("data/alaska_population.csv",stringsAsFactors = F)
head(pop)

```

## Spatial joins and summaries
* st_join function. requires 'join' function, and two objects of class 'sf'
* predicate functions define what you want to do
* st_within: which of the points are within which polygons
* If you had lines...maybe st_intersects, st_crosses. See options in ?st_join

Often, datasets have an INHERINT CRS, even if its not defined. With lat/lon data provided, its OFTEN WGS84. That CRS has to be told to R. THat's what were' doing here. 

LATER in analysis that CRS may be transformed to do other things.

```{r}
# Right now our "pop" data aren't represented in R as a spatial object.
# It can be, b/c it has lat/lon data
# Coerce "pop" into sf object
class(pop)
pop_4326 <- st_as_sf(pop, 
                     coords = c('lng','lat'),
                     crs = 4326, # good bet if not given. this is the INHERINT crs. Need to assign it here for R to know about it. Only after defined can you TRANSFORM it to 3338.
                     remove = F) # keep lng, lat around

head(pop_4326)
```
```{r}
#pop_joined = st_join(pop_4326, ak_regions_3338, join = st_within) # error, CRS not the same. Need to transform 4326 to 3338. 

pop_3338 <- pop_4326 %>% 
  st_transform(crs = 3338)

pop_joined = st_join(pop_3338, ak_regions_3338, join = st_within)

plot(pop_joined)
```
### Calculate population by region

```{r}

# This groups teh points and assigns them each the value of the total_pop of that region
# Not really what we want. 
pop_region <- pop_joined %>% 
  group_by(region) %>% 
  summarise(total_pop = sum(population))

head(pop_region)
plot(pop_region)
```

```{r}
?sf::tidyverse # tidyverse methods of sf objects

# Need to drop the geometry to do the summarise, then join the geometry back
# which we do in "pop_region_3338"

pop_region <- pop_joined %>% 
  as.data.frame %>% 
  group_by(region) %>% 
  summarise(total_pop = sum(population))

head(pop_region)
plot(pop_region)

pop_region_3338 <- left_join(ak_regions_3338, pop_region, by = "region")

head(pop_region_3338)
plot(pop_region_3338) #  data are what we want, going to plot in a pretty way.
```

```{r}
# Example using group_by with spatial data
pop_mgmt_3338 <- pop_region_3338 %>% 
  group_by(mgmt_area) %>% 
  summarise(total_pop = sum(total_pop))

head(pop_mgmt_3338)
plot(pop_mgmt_3338["total_pop"])
```

```{r}
# write out spatial objects to a set of shape files
write_sf(pop_region_3338, "data/ak_regions_pop.shp", delete_layer = T)

```

```{r}
rivers_3338 <- read_sf("data/ak_rivers_simp.shp")
st_crs(rivers_3338) # proj4string is same as saying epsg = 3338. can google
```


## Make maps!
* `sf` is part of tidyverse, so it works well with ggplot
* `geom_sf` will find lat/lon, map geometry. Dont need to give it explicitly.
* in mapping, we will layer data. Nice to leave ggplot() unassigned, and then explicitly assign data to each layer as we go. 

```{r}
# Labels = comma. Comes from scales package (allows you to manipulate scales in ggplot 
# easily). 
# scale_fill_continuous: generates a color gradient on the fly using r color words
# aes() shows point or line
ggplot() +
  geom_sf(data = pop_region_3338, aes(fill = total_pop)) + 
  geom_sf(data = rivers_3338, aes(size = StrOrder),color="black") +
  geom_sf(data = pop_3338, aes(), size = 0.5) + 
  scale_size(range = c(0.01,0.2),guide=F) +
  theme_bw() + 
  labs(fill = "Total Population") + 
  scale_fill_continuous(low = "lightblue", high = "purple", labels = comma)
  
```

## GGMAP
* A way to incorporate base maps into static maps. Will grab raster tiles from open servers. Like open street map. Will plot those under your data.
* Uses 3857 - a psuedo mercado projection

```{r}
pop_3857 <- pop_3338 %>% 
  st_transform(crs = 3857)
```

Get a basemap from Stamen Maps...
But first, we need this bug fix function

```{r}
# Define a function to fix the bbox to be in EPSG:3857
# See https://github.com/dkahle/ggmap/issues/160#issuecomment-397055208
ggmap_bbox_to_3857 <- function(map) {
  if (!inherits(map, "ggmap")) stop("map must be a ggmap object")
  # Extract the bounding box (in lat/lon) from the ggmap to a numeric vector, 
  # and set the names to what sf::st_bbox expects:
  map_bbox <- setNames(unlist(attr(map, "bb")), 
                       c("ymin", "xmin", "ymax", "xmax"))
  
  # Coonvert the bbox to an sf polygon, transform it to 3857, 
  # and convert back to a bbox (convoluted, but it works)
  bbox_3857 <- st_bbox(st_transform(st_as_sfc(st_bbox(map_bbox, crs = 4326)), 3857))
  
  # Overwrite the bbox of the ggmap object with the transformed coordinates 
  attr(map, "bb")$ll.lat <- bbox_3857["ymin"]
  attr(map, "bb")$ll.lon <- bbox_3857["xmin"]
  attr(map, "bb")$ur.lat <- bbox_3857["ymax"]
  attr(map, "bb")$ur.lon <- bbox_3857["xmax"]
  map
}
```


```{r}
# get tiles
# ?get_stamenmap
bbox <- c(-175, 52, -130, 68)
ak_map <- get_stamenmap(bbox, zoom = 4)
ak_map_3857 <- ggmap_bbox_to_3857(ak_map)
class(ak_map_3857)
```

```{r}
# plot basemap tiles and population data
# inherit.aes = F: dont inherit aes from ggmap
ggmap(ak_map_3857) + 
  geom_sf(data = pop_3857, aes(color = population), inherit.aes = F) + 
  scale_color_continuous(low = "khaki", high = "firebrick", labels = comma)
```

## Leaflet
Leaflet projects data for you, but expects input data in WGS84 (4326). 
It will project for us in 3338, when we tell it to (below, in options...crs = epsg3338)
`leaflet(options = leafletOptions(crs = epsg3338))`

```{r}
# Define leaflet projection
# C/P 

epsg3338 <- leaflet::leafletCRS(
  crsClass = "L.Proj.CRS",
  code = "EPSG:3338",
  proj4def =  "+proj=aea +lat_1=55 +lat_2=65 +lat_0=50 +lon_0=-154 +x_0=0 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs",
  resolutions = 2^(16:7))

```

```{r}
pop_region_4326 <- pop_region_3338 %>% 
  st_transform(crs = 4326)
```

```{r}
m <- leaflet(options = leafletOptions(crs = epsg3338)) %>%
        addPolygons(data = pop_region_4326, 
                    fillColor = "gray",
                    weight = 1)

m
```
```{r}
# Add labels, legends, color scale
# NOTE: anything you can put in an html script you can put in a leaflet popup. Including graphs etc. 

pal <- colorNumeric(palette = "Reds", domain = pop_region_4326$total_pop)

m <- leaflet(options = leafletOptions(crs = epsg3338)) %>%
        addPolygons(data = pop_region_4326, 
                    fillColor = ~pal(total_pop),
                    weight = 1,
                    color = "black",
                    fillOpacity = 1,
                    label = ~region) %>% 
        addLegend(position = "bottomleft",
                  pal = pal,
                  values = range(pop_region_4326$total_pop),
                  title = "Total Population")

m
```

```{r}
# Show in 4326, with basemap tiles from openstreetmap (live). But only in 4326 for this. 
m <- leaflet() %>%
        addTiles() %>% 
        addPolygons(data = pop_region_4326, 
                    fillColor = ~pal(total_pop),
                    weight = 1,
                    color = "black",
                    fillOpacity = 1,
                    label = ~region) %>% 
        addLegend(position = "bottomleft",
                  pal = pal,
                  values = range(pop_region_4326$total_pop),
                  title = "Total Population")

m
```


# Raster Analysis
(Julien)

[Ch18](https://science-for-nature-and-people.github.io/2020-data-collab-workshop/2020-02-snapp/raster-analysis.html)

```{r}
library(raster)

# Get raster
lc_3338 <- raster("/home/shares/scientist/ds-workshop/ak_nlcd_2011_landcover_50m_3338.tif")

lc_3338
```

```{r}
plot(lc_3338) # will take a min. 
plot(pop_3338, add = T) # dont' do this
```
## Extract the most frequent land cover

```{r}
# 500 - in meters becuase of current crs of lc_3338 
# buffer = 500. here means that we are taking the mode at circle centered at each point, with a radius of 500m. 

crs(lc_3338)
raster_points <- extract(lc_3338, pop_3338, buffer=500, fun=modal) # extract can do a lot. ?raster::extract
raster_points # a vector with all the values corresponding to the locations. same order as input (pop_3338)

# Add to pop_joined
pop_joined$land_cover <- raster_points 
View(pop_joined)
```

### 
Check out metadata. 
[MRLC dataset](https://www.mrlc.gov/data/legends/national-land-cover-database-2011-nlcd2011-legend)

Load legend
```{r}
# Load csv of legend
legend_lc <- read.csv("/home/shares/scientist/ds-workshop/legend_ak_nlcd_2011.csv", stringsAsFactors = F)

head(legend_lc)
head(pop_joined)

```

### Recategorize
Check out how ifelse is similar to excel. 

Recategoriize ID from legend into land cover categories (known from the metadata on the site)
```{r}
# Recategorize
# It is a lot of categories, let us consolidate this
legend_lc <- legend_lc %>%
  mutate(main_lc = ifelse(ID %in% 40:49, "Forest",
                              ifelse(ID %in% 20:29, "Urban",
                                     ifelse(ID %in% 50:59, "Shrub",
                                             ifelse(ID %in% 70:79, "Grass",
                                                     ifelse(ID %in% 80:89, "Crops",
                                                             ifelse(ID %in% 90:99, "Wetland", Land.Cover.Type)
                                                             )
                                                     )
                                             )
                                     )
                              )
  )

View(legend_lc) # Some of main_lc are left as "Land.Cover.Type". We will be dropping those. 

# Join the LC categories to the population data
pop_3338_cover <- left_join(pop_joined, legend_lc, by=c("land_cover"="ID")) %>% 
  dplyr::select(-Red, -Green, -Blue, -Land.Cover.Type)

head(pop_3338_cover)
```


```{r}
# Create color palette by keeping last color of each group
pal <- legend_lc %>% 
  group_by(main_lc) %>% 
  slice(n()) %>% # Keeping the last color of the groups
  ungroup %>% 
  arrange(ID) %>%
  mutate(color_hex = rgb(Red, Green, Blue, max = 255)) %>% 
  dplyr::select(main_lc, color_hex)

# turn pallete into a list for plotting
# a named list that can be passed to ggplot
pal_list <- pal$color_hex
names(pal_list) <- pal$main_lc


# Plot by region
ggplot(pop_3338_cover, aes(region, population, fill = main_lc)) +
    geom_col() +
    scale_y_continuous(labels = comma) +
    scale_fill_manual(values = pal_list) +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
    ggtitle("Land cover type by region and population") +
    labs(fill = "", y = "Population", x = "")
```

```{r}

ggplot() +
    geom_sf(data = ak_regions_3338, aes(), color = "black") +
    geom_sf(data = pop_3338_cover, aes(color = main_lc,
                                       size = population), show.legend = "point") +
    scale_size_continuous(guide = F) +
    scale_color_manual(values = pal_list) +
    theme_bw() +
    theme(legend.position = "bottom", legend.title = element_blank())

```

## Raster Analysis

Raster manipulation in R is slow. Can lower resolution or take a subset. 
`crop` will help (using any other shape)

Start by cropping.

```{r}
# Cropping the Copper River region

copper_region_3338 <- ak_regions_3338 %>% 
  filter(region == "Copper River") 

plot(copper_region_3338)
```

```{r}
copper_lc_3338 <- crop(lc_3338, copper_region_3338) # crop(raster object, extend to which you want to crop)
plot(copper_lc_3338)
```

Defining forest mask function
forest:not

always get the value and then operate on it. dont do "raster*2" etc otherwise will be very slow.
```{r}

forest_masker <- function(pixel_val){
  # if a pixel is outside of 40-49, assign 0
  pixel_val[pixel_val < 40 | pixel_val > 49] <- 0
  # if pixel is between 40-49, assing 1
  pixel_val[pixel_val >= 40 & pixel_val <= 49] <- 1
  
  return(pixel_val)
}

```

```{r}
# calc takes raster, function
# the fucntion "forest_masker" is taking care of value-by-value operation, even though 
# we gave 'calc' the whole (cropped) raster
copper_forested_3338 <- calc(copper_lc_3338, forest_masker)
plot(copper_forested_3338)

```

Select copper river pop to count % forest

```{r}
# Filter the population data for the copper region to get Copper River locations
copper_pop_3338 <- pop_3338_cover %>%
  filter(region == "Copper River")

# Use those locations to extract the number of pixels wth forest from the raster layer "copper_forested_3338"
forested_count <- extract(copper_forested_3338, copper_pop_3338, buffer=500, fun=sum)

# add back into main dataset
copper_pop_3338$forest_cov <- 100 * forested_count / (20*20) # 20 pixels within the diameter of the pixel
head(copper_pop_3338)
```

Plotting the percentage of forested area in the 1 km^2 surround of the population centers:

```{r}
ggplot() +
    geom_sf(data = copper_region_3338, aes(), color = "black") +
    geom_sf(data = copper_pop_3338, aes(color = forest_cov,
                                       size = population)) +
    scale_size_continuous(guide = F) +
    scale_colour_gradientn(colours = terrain.colors(10, rev=TRUE)) +
    theme_bw() +
    theme(legend.position = "bottom") +
    labs(color = "Percent Forest Cover")
```
## NOTES on Rasters
Raster analysis can be SLOW. See book for ideas on how to speed up
(crop, downsample).
Before starting the processing of large raster, we strongly recommend you read this information: https://rspatial.org/raster/appendix1.html

Also consider using python...
